---
title: "2_nuseds_cuid_pse"
author: "Bruno S. Carturan"
date: "2025-02-27"
output: 
  html_document:
    toc: true                  # Adds a table of contents to the document
    toc_float: true           # Makes the table of contents float on the side as the reader scrolls.
    toc_collapsed: true        # Starts the table of contents in a collapsed state.
    toc_depth: 3               # Specifies the depth of headers (e.g., ##, ###) to include in the table of contents.
    number_sections: true      # 
    theme: journal  # lumen
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

The goal of the script is to associate each population (defined by the fields `POP_ID` = `IndexId`, the latter also specifying the species acronym) in the **cleaned NuSEDS** dataset (i.e., *NuSEDS_escapement_data_collated_DATE.csv*) to the conservation unit identidication number `cuid`, as defined in the Pacific Salmon explorer ([PSE](https://www.salmonexplorer.ca/)). The cleaning procedure is coded in the script *1_nuseds_collation.rmd* and is visible in [1_nuseds_collation.html](https://bookdown.org/salmonwatersheds/nuseds_cleaning_procedure/1_nuseds_collation.html).


```{r,include=FALSE}

#'******************************************************************************
#' The goal of the script is to 
#' 
#' Previous script: Fraser_salmon_CU_updates.Rmd
#' 
#' 
#' Files imported (from dropbox):
#' - streamlocationids.csv
#' - conservationunits_decoder.csv
#' - streamspawnersurveys_output.csv
#' - 1_NuSEDS_escapement_data_collated_DATE.csv
#'
#' Files produced: 
#' - 2_nuseds_cuid_streamid_DATE.csv
#' 
#'******************************************************************************

rm(list = ls())
graphics.off()

# reset the wd to head using the location of the current script
path <- rstudioapi::getActiveDocumentContext()$path
dirhead <- "population-indicators"
path_ahead <- sub(pattern = paste0("\\",dirhead,".*"),replacement = "", x = path)
wd_head <- paste0(path_ahead,dirhead)
setwd(wd_head)

# Now import functions related to directories.
# Note that the script cannot be called again once the directory is set to the 
# subdirectory of the project (unless setwd() is called again).
source("code/functions_set_wd.R")
source("code/functions_general.R")

# return the name of the directories for the different projects:
subDir_projects <- subDir_projects_fun()

wds_l <- set_working_directories_fun(subDir = subDir_projects$spawner_surveys,
                                     Export_locally = F)
wd_head <- wds_l$wd_head
wd_project <- wds_l$wd_project
wd_code <- wds_l$wd_code
wd_data <- wds_l$wd_data
wd_figures <- wds_l$wd_figures
wd_output <- wds_l$wd_output
wd_X_Drive1_PROJECTS <- wds_l$wd_X_Drive1_PROJECTS

wd_references_dropbox <- paste(wd_X_Drive1_PROJECTS,
                               wds_l$wd_project_dropbox,
                               "references",sep="/")

wd_data_dropbox <- paste(wd_X_Drive1_PROJECTS,
                         wds_l$wd_project_dropbox,
                         "data",sep="/")

wd_documents <- paste(wd_project,"documents",sep="/")

wd_pop_indic_data_input_dropbox <- paste(wd_X_Drive1_PROJECTS,
                                         wds_l$wd_population_indicator_data_input_dropbox,
                                         sep = "/")

wd_pop_indic_data_gis_dropbox <- gsub("input","gis",wd_pop_indic_data_input_dropbox)

# Loading packages & functions
library(tidyr)
library(dplyr) # for arrange()
library(sf)
library(sp)     # for spDists() TERRA is the replacement
library(scales)

source("code/functions.R")


#'* !!! DECISIONS TO MAKE !!! *

# Set tp true to update the datasets
export_datasets <- F

#' Decision made in 1_nuseds_collation.rmd: ## Remove the IndexId & GFE_ID time series in NUSEDS with only NAs and/or 0s
#' If TRUE, time series only composed of NAs and/or 0s are removed from NUSEDS; 
#' If FALSE, time series only composed of NAs are removed from NUSEDS.
#' Setting to T or F will import the corresponding dataset.
remove_timeSeries_zeros_too <- T 

#' Decision made in 1_nuseds_collation.rmd: Used just after NUSEDS and CUSS are merged,
#'to decide if we want to replace all the remaining 0s by NAs.
#' Setting to T or F will import the corresponding dataset.
replace_zeros_byNAs <- T

```

# Import datasets

Import the cleaned NuSEDS dataset with the following decisions made concerning zeros:

```{r, include=FALSE}

#'* Import the log file *
logfile_path <- paste0(getwd(),"/spawner-surveys/output/1_log_file.csv")
logfile_path <- gsub("spawner-surveys/code/","",logfile_path)
log_file <- read.csv(logfile_path,header = T)

# selected the rows corresponding to the decision made concerning including or 
# not the 0s:
cond <- log_file$remove_timeSeries_zeros_too == remove_timeSeries_zeros_too & 
  log_file$replace_zeros_byNAs == replace_zeros_byNAs
# select the most recent date:
date_export <- max(log_file[cond,]$date_export)


#'* Import the most recent NuSEDS_escapement_data_collated file *
# nuseds <- import_mostRecent_file_fun(wd = paste0(wd_output,"/archive"), 
#                                      pattern = "NuSEDS_escapement_data_collated")

nuseds <- read.csv(paste0(wd_output,"/archive/1_NuSEDS_escapement_data_collated_",date_export,".csv"),header = T)

head(nuseds)
nrow(nuseds) # 310255 309338 306823 306999

nrow(unique(nuseds[,c("SPECIES_QUALIFIED","POP_ID","SYSTEM_SITE","WATERBODY")])) # 6892 6854 6868
nrow(unique(nuseds[,c("SPECIES_QUALIFIED","POP_ID","SYSTEM_SITE","WATERBODY","GFE_ID")])) # 6892 6854 6868

sum(nuseds$MAX_ESTIMATE == 0 & !is.na(nuseds$MAX_ESTIMATE)) # 0
sum(is.na(nuseds$MAX_ESTIMATE)) # 157808 157264 155984
```

```{r,echo=FALSE}

if(remove_timeSeries_zeros_too){
  print("Time series only composed of NAs AND/OR zeros were removed from NUSEDS in the early cleaning process in 1_nuseds_collation.rmd.")
}else{
  print("Time series only composed of NAs were removed from NUSEDS in the early cleaning process in 1_nuseds_collation.rmd, zeros were left.")
}

if(replace_zeros_byNAs){
  print("Zeros were replaced by NAs in the late cleaning process in 1_nuseds_collation.rmd.")
}else{
  print("Zeros were NOT replaced by NAs in the late cleaning process in 1_nuseds_collation.rmd.")
}

```
The PSE file *conservationunits_decoder.csv* is imported; this is the file containing the current `cuid` associated to NuSEDS's `FULL_CU_IN` (named `cu_index` in the decoder file).

```{r,include=FALSE}

#'Import the name of the different datasets in the PSF database and their 
#' corresponding CSV files.
datasetsNames_database <- datasetsNames_database_fun()

fromDatabase <- update_file_csv <- F

#'* Import the conservationunits_decoder.csv *
#' from population-indicators/data_input or download it from the PSF database.
#' # To obtain the generation length and calculate the the "current spawner abundance".
conservationunits_decoder <- datasets_database_fun(nameDataSet = datasetsNames_database$name_CSV[1],
                                                   fromDatabase = fromDatabase,
                                                   update_file_csv = update_file_csv,
                                                   wd = wd_pop_indic_data_input_dropbox)

head(conservationunits_decoder)

# check the CUs with is.na(cu_index):
sum(is.na(conservationunits_decoder$cu_index))    # 45
sum(is.na(conservationunits_decoder$cu_name_pse))
cond <- is.na(conservationunits_decoder$cu_index)
conservationunits_decoder[cond,]
```

Import the *streamlocationids.csv* to access the location names, coordinates and identification number for maintaining consistency.

TEMPORARY: change the name of the field `streamid` to `cu_stream_id` because the latter is the unique association between a CU (`cuid`) and a location/stream (`GFE_ID`).

```{r, include=FALSE}
#'* Files from PSF database *

#'Import the name of the different datasets in the PSF database and their 
#' corresponding CSV files.
datasetsNames_database <- datasetsNames_database_fun()

fromDatabase <- update_file_csv <- F

#' Import streamlocationids to obtain the streamID 
streamlocationids <- datasets_database_fun(nameDataSet = "streamlocationids.csv", # datasetsNames_database$name_CSV[9],
                                           fromDatabase = fromDatabase,
                                           update_file_csv = update_file_csv,
                                           wd = wd_pop_indic_data_input_dropbox)

rownames(streamlocationids) <- NULL
colnames(streamlocationids)[colnames(streamlocationids) == "streamid"] <- "cu_stream_id"
head(streamlocationids)
```

Import the regions' shape files are imported. These represent the geographic boundaries as displayed in the PSE.

```{r, include=FALSE}
#'* Import the shape files for the Region boundaries  *
# wd_maps_rg <- gsub("1_PROJECTS","5_DATA",wd_X_Drive1_PROJECTS) # files not up to date
# wd_maps_rg <- gsub("1_PROJECTS","5_DATA",wd_X_Drive1_PROJECTS)
# wd_maps_rg <- paste0(wd_pop_indic_data_gis_dropbox,"/se_boundary_regions")
regions_shp <- st_read(paste0(wd_pop_indic_data_gis_dropbox,"/se_boundary_regions/se_boundary_regions.shp")) %>%
  st_transform(crs = 4269)
unique(regions_shp$regionname)
sf_use_s2(FALSE) # so that st_intersects() and st_simplify() can be used
regions_shp_full <- regions_shp
regions_shp <- st_simplify(x = regions_shp, dTolerance = .002) # .001 # to reduce computation time

```


# Updates on FULL_CU_IN/cu_index

## In conservationunits_decoder (TEMPORARY)

The updates below are done here until the changes are made directly in *conservationunits_decoder.csv*.

```{r, echo=FALSE}

d_fixes <- data.frame(cuid = c(528,756,758,759,760,761,763,1022),
                      cu_index_old = c("SX_528","","","","","","","SER-023"),
                      cu_index_new = c("SEL-16-01","SEL-03-07","SEL-05-01","SEL-06-19",
                                        "SEL-09-04","SEL-09-05","SEL-10-02","SER-23"))

for(r in 1:nrow(d_fixes)){
  cuid <- d_fixes$cuid[r]
  cu_index_new <- d_fixes$cu_index_new[r]
  cond <- conservationunits_decoder$cuid == cuid
  conservationunits_decoder$cu_index[cond] <- cu_index_new
}

d_fixes
```

## In NuSEDS

The `FULL_CU_IN` of several population is updated to reflect (1) partition of the Sockeye CU `FULL_CU_IN` = "SEL-21-02" into sub-groups (EW: 'Early Wild', for Babine/Onerka; LW: 'Late Wild' for Nilkitkwa, and F: Fulton and Pinkut) as in [DFO 2023](https://waves-vagues.dfo-mpo.gc.ca/library-bibliotheque/41102356.pdf); (2) recent corrections for the Bella Coola River-Late CU (CM-17) and Bella Coola-Dean Rivers (CM-16) (personal communication from Carrie Holt, DFO, May 2023).

```{r, echo=FALSE}
#'* Edit FULL_CU_IN for several POP_IDs * 
# Corrections in CU assignment for central coast chum from Carrie Holt
# https://salmonwatersheds.slack.com/archives/C017N5NSCJY/p1683774240661029?thread_ts=1683735939.696999&cid=C017N5NSCJY
# https://salmonwatersheds.slack.com/archives/CJ5RVHVCG/p1705426563165399?thread_ts=1705344122.088409&cid=CJ5RVHVCG

nuseds$FULL_CU_IN_PSE <- nuseds$FULL_CU_IN

#' Import the corrections:
full_cu_l <- update_for_FULL_CU_IN_l()

show <- NULL
for(i in 1:length(full_cu_l)){
  # i <- 5
  FULL_CU_IN_here <- names(full_cu_l)[i]
  # print(FULL_CU_IN_here)
  
  POP_IDs_here <- full_cu_l[[i]]
  
  #
  cond_nuseds <- nuseds$POP_ID %in% POP_IDs_here
  
  if(any(cond_nuseds)){
    show_here <- unique(nuseds[cond_nuseds,c("POP_ID","FULL_CU_IN")])
  
    cond_decoder <- conservationunits_decoder$cu_index == FULL_CU_IN_here &
      !is.na(conservationunits_decoder$cu_index)
  
    if(!any(cond_decoder)){
      print("not match for FULL_CU_IN_here in decoder - BREAL")
      break
    
    }else{
      show_here$region <- unique(conservationunits_decoder$region[cond_decoder])
      show_here$species_name <- unique(conservationunits_decoder$species_name[cond_decoder])
      show_here$FULL_CU_IN_PSE <- FULL_CU_IN_here
      show_here <- show_here[,c(3,4,1,2,5)]
      rownames(show_here) <- NULL
    
      if(is.null(show)){
        show <- show_here
      }else{
        show <- rbind(show,show_here)
      }
      
      nuseds$FULL_CU_IN_PSE[cond_nuseds] <- FULL_CU_IN_here
    }
  }
}

show
```

The `CU_NAME` of the river Sockeye at `SYSTEM` = "BELLA COOLA RIVER" (`GFE_ID` = 968) is changed from:

```{r, echo=FALSE}
#'* FIX: South Atnarko Lakes *
#' GFE_ID 968 for sockeye should be attributed to South Atnarko Lakes CU 
#' (cf. Population meeting from 05/03/2024)
cond <- nuseds$GFE_ID == 968 & nuseds$SPECIES_QUALIFIED %in% c("SEL","SER")
# unique(nuseds$CU_NAME[cond]) # "NORTHERN COASTAL FJORDS"
# unique(nuseds$SPECIES_QUALIFIED[cond]) # SER
# unique(nuseds$SYSTEM_SITE[cond]) # "BELLA COOLA RIVER"

show <- unique(nuseds[cond,c("SPECIES_QUALIFIED","CU_NAME","SYSTEM_SITE","GFE_ID")])
rownames(show) <- NULL
show
```

to:

```{r, echo=FALSE}
nuseds$CU_NAME[cond] <- toupper("South Atnarko Lakes")
show <- unique(nuseds[cond,c("SPECIES_QUALIFIED","CU_NAME","SYSTEM_SITE","GFE_ID")])
rownames(show) <- NULL
show
```

# Edits on Methods

## Create stream_survey_quality from ESTIMATE_CLASSIFICATION

We create the field `stream_survey_quality` from `ESTIMATE_CLASSIFICATION` such as:

```{r, echo=FALSE}

#'* Create stream_survey_quality from ESTIMATE_CLASSIFICATION *
#' cf. Table 4.5 in section 4.1.3 of the Tech Report
estim_class_nuseds <- unique(nuseds$ESTIMATE_CLASSIFICATION)

nuseds$stream_survey_quality <- NA
for(ecn in estim_class_nuseds){
  # ecn <- estim_class_nuseds[1]
  cond_nuseds <- nuseds$ESTIMATE_CLASSIFICATION == ecn
  
  if(ecn == "TRUE ABUNDANCE (TYPE-1)"){
    out <- "High"
  }else if(ecn == "TRUE ABUNDANCE (TYPE-2)"){
    out <- "Medium-High"
  }else if(ecn == "RELATIVE ABUNDANCE (TYPE-3)"){
    out <- "Medium"
  }else if(ecn == "RELATIVE ABUNDANCE (TYPE-4)"){
    out <- "Medium-Low"
  }else if(ecn %in% c("RELATIVE ABUNDANCE (TYPE-5)",
                      "RELATIVE: CONSTANT MULTI-YEAR METHODS")){
    out <- "Low"
  }else if(ecn %in% c("PRESENCE/ABSENCE (TYPE-6)",
                      "PRESENCE-ABSENCE (TYPE-6)",
                      "RELATIVE: VARYING MULTI-YEAR METHODS")){
    out <- "Low"
  }else if(ecn == "UNKNOWN"){
    out <- "Unknown"
  }else if(ecn %in% c("","NO SURVEY THIS YEAR","NO SURVEY")){
    out <- NA
  }else{
    print(ecn)
  }
  #print(out)
  nuseds$stream_survey_quality[cond_nuseds] <- out
}

show <- unique(nuseds[,c("ESTIMATE_CLASSIFICATION","stream_survey_quality")])
rownames(show) <- NULL

ESTIMATE_CLASSIFICATION <- c("TRUE ABUNDANCE (TYPE-1)",
                             "TRUE ABUNDANCE (TYPE-2)",
                             "RELATIVE ABUNDANCE (TYPE-3)",
                             "RELATIVE ABUNDANCE (TYPE-4)",
                             "RELATIVE ABUNDANCE (TYPE-5)",
                             "PRESENCE-ABSENCE (TYPE-6)",
                             "RELATIVE: CONSTANT MULTI-YEAR METHODS",
                             "RELATIVE: VARYING MULTI-YEAR METHODS",
                             "UNKNOWN",
                             "NO SURVEY THIS YEAR")

order <- order(factor(x = show$ESTIMATE_CLASSIFICATION, levels = ESTIMATE_CLASSIFICATION))
show <- show[order,]
show
```

## Fixes in ESTIMATE_METHOD 

We make the following corrections to the field `ESTIMATE_METHOD`:

```{r, echo=FALSE}

#'* Fixes in the methods *
# Katy's request:
# https://salmonwatersheds.slack.com/archives/C03LB7KM6JK/p1712611492405689?thread_ts=1712252256.802999&cid=C03LB7KM6JK

# unique(nuseds$ESTIMATE_METHOD)

estMeth <- data.frame(ESTIMATE_METHOD = c("Cummulative","Unknown","Fixed Site Census",
                                          "Aerial","Fence", "Insufficient Information"),
                      correction = c("Cumulative","Unknown Estimate Method","Fence Count",
                                     "Aerial Survey","Fence Count","Unknown Estimate Method"))


estMeth

for(r in 1:nrow(estMeth)){
  # r <- 2
  if(estMeth$ESTIMATE_METHOD[r] == "Cummulative"){
    nuseds$ESTIMATE_METHOD <- gsub("Cummulative","Cumulative",nuseds$ESTIMATE_METHOD)
  }else{
    cond <- nuseds$ESTIMATE_METHOD == estMeth$ESTIMATE_METHOD[r]
    nuseds$ESTIMATE_METHOD[cond] <- estMeth$correction[r]
  }
}

```

# Find the cuid from FULL_CU_IN_PSE

We associate the previously defined field `FULL_CU_IN_PSE` to the PSE's `cuid`, `cu_name_pse`, `cu_name_dfo`, `region`, using the *conservationunits_decoder.csv*. For instance:

```{r, include=FALSE}

#'* Provide a cuid to each row in nuseds using conservationunits_decoder *
#' using: FULL_CU_IN_PSE

nuseds$cuid <- NA
nuseds$cu_name_pse <- NA
nuseds$cu_name_dfo <- NA
nuseds$region <- NA
nuseds$regionid <- NA

FULL_CU_IN_PSE <- unique(nuseds$FULL_CU_IN_PSE)
# length(FULL_CU_IN_PSE) # 411
# sum(is.na(FULL_CU_IN_PSE)) # 0

cuid_cu_index <- data.frame(FULL_CU_IN_PSE = FULL_CU_IN_PSE)
cuid_cu_index$cuid <- NA
cuid_cu_index$CU_NAME <- NA
for(r in 1:nrow(cuid_cu_index)){
  fci <- cuid_cu_index$FULL_CU_IN_PSE[r]
  cond <- conservationunits_decoder$cu_index == fci & !is.na(conservationunits_decoder$cu_index)
  cond2 <- nuseds$FULL_CU_IN_PSE == fci
  CU_NAME <- paste(unique(nuseds$CU_NAME[cond2]), collapse = "; ") # the upates done above creates three instance where more than one CU_NAME is returned for one unique FULL_CU_IN_PSE in nuseds
  cuid_cu_index$CU_NAME[r] <- CU_NAME
  
  # if(length(unique(nuseds$CU_NAME[cond2])) > 1){ # check ; but these are due to the changes made above with update_for_FULL_CU_IN_l()
  #   print(cuid_cu_index[r,])
  #   print(unique(nuseds$CU_NAME[cond2]))
  #   print("***")
  # }
  
  if(any(cond)){
    cuid_cu_index$cuid[r] <- unique(conservationunits_decoder$cuid[cond])
    nuseds$cuid[cond2] <- unique(conservationunits_decoder$cuid[cond])
    nuseds$cu_name_pse[cond2] <- unique(conservationunits_decoder$cu_name_pse[cond])
    nuseds$cu_name_dfo[cond2] <- unique(conservationunits_decoder$cu_name_dfo[cond])
    nuseds$region[cond2] <- unique(conservationunits_decoder$region[cond])
  }
}
```

```{r, echo=FALSE}
show <- unique(nuseds[,c("region","SPECIES","CU_NAME","cu_name_dfo","cu_name_pse","FULL_CU_IN_PSE","cuid")])

rownames(show) <- NULL
head(show)
```

```{r, include=FALSE}
#'* Check the FULL_CU_IN not in the decoder: *
cond_NA <- is.na(cuid_cu_index$cuid)
head(cuid_cu_index)
sum(cond_NA) # 23

cu_index_NA <- cuid_cu_index[cond_NA,]
colnames(cu_index_NA)[colnames(cu_index_NA) == "FULL_CU_IN_PSE"] <- "FULL_CU_IN"

rownames(cu_index_NA) <- NULL
```

There are `r nrow(cu_index_NA)` `FULL_CU_IN` that are not in *conservationunits_decoder.csv*. We use the regions's shape file to find their respective region:

```{r,echo=FALSE}

# Find the coordinates
cu_index_NA$CU_LAT <- sapply(cu_index_NA$FULL_CU_IN,function(cui){
  cond <- nuseds$FULL_CU_IN == cui
  return(unique(nuseds$CU_LAT[cond]))
})

cu_index_NA$CU_LONGT <- sapply(cu_index_NA$FULL_CU_IN,function(cui){
  cond <- nuseds$FULL_CU_IN == cui
  return(unique(nuseds$CU_LONGT[cond]))
})

#' Find the corresponding region:
cu_index_NA$region <- NA
for(r in 1:nrow(cu_index_NA)){
  # r <- 1
  point <- st_as_sf(cu_index_NA[r,], 
                    coords = c("CU_LONGT","CU_LAT"), crs = 4269)
  
  layer_rg <- st_intersects(point, regions_shp)
  if(length(layer_rg[[1]]) == 0){ # no match, try to buffer
    layer_rg <- st_intersects(point, st_buffer(x = regions_shp, dist = .001))
  }
  
  if(length(layer_rg[[1]]) == 0){ # no match, try to buffer
    layer_rg <- st_intersects(point, st_buffer(x = regions_shp, dist = .002))
  }
  
  if(length(layer_rg[[1]]) == 0){ # no match, try to buffer
    print("Still no region found - BREAK")
    break
  }
  
  if(length(layer_rg[[1]]) > 1){ # 
    print("More than one region found - BREAK")
    break
  }
  
  layer_rg <- layer_rg[[1]]
  cu_index_NA$region[r] <- regions_shp$regionname[layer_rg]
}

cu_index_NA
```

```{r, include=FALSE}
# used to be cuid 751
cond_751 <- grepl(simplify_string_fun("Adams and Momich Lakes_Early Summer"),
              simplify_string_fun(nuseds$CU_NAME))
nuseds[cond_751,]$WATERBODY |> unique()
nuseds[cond_751,]$CU_NAME |> unique()
nuseds[cond_751,]$FULL_CU_IN |> unique()

nuseds[cond_751 , c("cuid","WATERBODY","Y_LAT","X_LONGT")] |> unique()
#  cuid            WATERBODY latitude_final longitude_final
#   751         BURTON CREEK       51.48255       -119.4648 --> 760  Adams-Early Summer
#   751 MOMICH RIVER - UPPER       51.31958       -119.3236 --> 761 Momich-Early Summer
#   751  ADAMS RIVER - UPPER       51.41090       -119.4561 --> 760  Adams-Early Summer
#   751         MOMICH RIVER       51.33461       -119.4232 --> 761 Momich-Early Summer
#   751        CAYENNE CREEK       51.32071       -119.3197 --> 761 Momich-Early Summer
```

The CU above with `FULL_CU_IN` = `r unique(nuseds[cond_751,]$FULL_CU_IN)` is separated into the two following CUs to reflect COSEWIC's grouping (note the creation of the field `cu_name_pse`):


```{r, echo=FALSE}
# UPDATE: 2024-11-21: the CU Fraser Sockeye Adams & Momich Lakes-Early Summer  
# 751 was split into the CUs with cuid 760 and 761. Consequently cuid 751 is not
# in the decoder anymore. For the sake of updating the data for the data demise
# paper, I add it here:
# This section should be removed in the next NuSEDS update.
# CU Fraser Sockeye Adams & Momich Lakes-Early Summer  751 that was split into CUs 760 and 761
# https://salmonwatersheds.slack.com/archives/C03LB7KM6JK/p1725753313593719?thread_ts=1725564850.867719&cid=C03LB7KM6JK
# cf. population meeting September 11 2024

nuseds$cu_name_pse <- NA

cond_760 <- cond_751 & nuseds$WATERBODY %in% c("BURTON CREEK","ADAMS RIVER - UPPER")
cond_761 <- cond_751 & nuseds$WATERBODY %in% c("MOMICH RIVER - UPPER","MOMICH RIVER",
                                               "CAYENNE CREEK")

nuseds$cuid[cond_760] <- 760
nuseds$cuid[cond_761] <- 761

for(cuid in 760:761){
  cond_nuseds <- nuseds$cuid == cuid & !is.na(nuseds$cuid)
  cond_decoder <- conservationunits_decoder$cuid == cuid
  nuseds$cu_name_pse[cond_nuseds] <- conservationunits_decoder$cu_name_pse[cond_decoder]
  nuseds$cu_name_dfo[cond_nuseds] <- conservationunits_decoder$cu_name_dfo[cond_decoder]
  nuseds$FULL_CU_IN_PSE[cond_nuseds] <- conservationunits_decoder$cu_index[cond_decoder]
  nuseds$region[cond_nuseds] <- conservationunits_decoder$region[cond_decoder]
}

show <- nuseds[cond_751,c("FULL_CU_IN","FULL_CU_IN_PSE","CU_NAME","cu_name_pse","cuid","WATERBODY")] |> unique()
rownames(show) <- NULL
show[order(show$cuid),]

# cond_751 <- grepl(simplify_string_fun("Adams and Momich Lakes_Early Summer"),
#               simplify_string_fun(nuseds$CU_NAME))
# nuseds[cond_751,]$cuid <- 751
# nuseds[cond_751,]$cu_name_pse <- "Adams & Momich Lakes-Early Summer"
# nuseds[cond_751,]$cu_name_dfo <- "Adams and Momich Lakes_Early Summer <<Extinct>>"
# nuseds[cond_751,]$regionid <- 4
# nuseds[cond_751,]$region <- "Fraser"

```

We show below the corresponding time series for the rest of the unmatched CUs:

```{r, echo=FALSE, fig.height=7.5, fig.width=10}
# update cu_index_NA
cond <- grepl(simplify_string_fun("Adams and Momich Lakes_Early Summer"),
              simplify_string_fun(cu_index_NA$CU_NAME))
cu_index_NA <- cu_index_NA[!cond,]

# produce figure time series
for(r in 1:nrow(cu_index_NA)){
  # r <- 1
  FULL_CU_IN <- cu_index_NA$FULL_CU_IN[r]
  cond <- nuseds$FULL_CU_IN == FULL_CU_IN
  IndexId_GFE_ID <- unique(nuseds[cond,c("IndexId","GFE_ID")])
  
  main <- paste(cu_index_NA$CU_NAME[r],
                cu_index_NA$FULL_CU_IN[r],
                sep = " - ")
  
  plot_IndexId_GFE_ID_fun(IndexIds = IndexId_GFE_ID$IndexId,
                          GFE_IDs = IndexId_GFE_ID$GFE_ID,
                          all_areas_nuseds = nuseds, 
                          main = c(cu_index_NA$region[r],main))
  legend("topright",paste0("r = ",r), bty = "n")
}
```

These time series are kept in the dataset but will be remove in the next step/script.


# Work on locations

fsafhkldn

## Corrections

There are two `LOCAL_NAME_1` with typos, which we replace by the value in `SYSTEM_SITE`:

```{r, echo=FALSE}
# Manual fix 1st:
#'-  "BARRI\xc8RE RIVER" --> "BARRIERE RIVER"
#'- "FRAN\xc7OIS LAKE" --> FRANCOIS LAKE"

cond1 <- nuseds$SYSTEM_SITE == "BARRIERE RIVER"
cond2 <- nuseds$SYSTEM_SITE == "FRANCOIS LAKE"

show <- unique(nuseds[cond1 | cond2,c("SYSTEM_SITE","WATERBODY","LOCAL_NAME_1","LOCAL_NAME_2")])
rownames(show) <- NULL

nuseds$LOCAL_NAME_1[cond1] <- "BARRIERE RIVER"
nuseds$LOCAL_NAME_1[cond2] <- "FRANCOIS LAKE"

show
```


##  Attribute cu_stream_id to nuseds

```{r,include=FALSE}
SYSTEM_SITE_fixes <- SYSTEM_SITE_fixes_fun()
SYSTEM_SITE_fixes <- data.frame(SYSTEM_SITE = SYSTEM_SITE_fixes$SYSTEM_SITE,
                                correction = SYSTEM_SITE_fixes$sys_nm)
```

We first edit the name of `r nrow(SYSTEM_SITE_fixes)` locations/streams names:

```{r,echo=FALSE}
SYSTEM_SITE_fixes
```




```{r}
SYSTEM_SITE <- unique(nuseds$SYSTEM_SITE)
for(r in 1:nrow(SYSTEM_SITE_fixes)){
  # r <- 1
  cond <- SYSTEM_SITE == SYSTEM_SITE_fixes$SYSTEM_SITE[r]
  if(any(cond)){
    SYSTEM_SITE[cond] <- SYSTEM_SITE_fixes$correction[r]
  }
}
  


SYSTEM_SITE_Extrafixes_fun(SYSTEM_SITE = , streamlocationids = )


GFE_ID <- unique(nuseds$GFE_ID)
sum(is.na(nuseds$GFE_ID)) # 0
length(GFE_ID) # 2325

cond <- ! SYSTEM_SITE %in% streamlocationids$sys_nm
sum(cond) # 526 487
SYSTEM_SITE[cond]
# are those location not found new compared to the last version or is it a typo issue in SYSTEM_SITE?

nuseds_cuid_previous <- read.csv(paste0(wd_output,"/archive/2_nuseds_cuid_streamid_2024-11-25.csv"),header = T)
cond <- ! SYSTEM_SITE %in% nuseds_cuid_previous$SYSTEM_SITE
sum(cond) # 11 --> only 11.

cond <- ! unique(nuseds_cuid_previous$SYSTEM_SITE) %in% streamlocationids$sys_nm
sum(cond) # 515

# try with the nused on the PSE

path <- "https://api.salmonwatersheds.ca/Data-Library/Download.aspx?file=~/ServerFiles/ExportedData/Shapefiles/dataset2_spawner_surveys.csv"
nuseds_cuid_previous2 <- read.csv(path,header = T)
cond <- ! SYSTEM_SITE %in% nuseds_cuid_previous2$stream_name_pse
sum(cond) # 576
cond <- ! SYSTEM_SITE %in% nuseds_cuid_previous2
sum(cond) # 576




cond <- ! streamlocationids$sys_nm %in% SYSTEM_SITE
sum(cond) # 1387
SYSTEM_SITE[cond]


unique(streamlocationids$regionid)

```










